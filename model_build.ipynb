{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Persisting an ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "import sklearn\n",
    "df = pd.read_csv('data/student-mat.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices = [229, 247, 346, 288, 143, 212, 258, 265, 189, 385, 106, 284, \n",
    "136, 327, 180, 174, 190, 99, 172, 306, 41, 391, 211, 226, 209, 168, 371, 154, \n",
    "85, 91, 310, 44, 72, 195, 287, 271, 255, 75, 241, 204, 133, 243, 7, 23, 140, 113, \n",
    "185, 5, 382, 268, 364, 210, 46, 305, 367, 389, 321, 119, 353, 236, 267, 39, 257, 393, \n",
    "63, 94, 50, 338, 330, 181, 203, 55, 13, 109, 196, 70, 264, 347, 62, 324, 331, 234, 238, \n",
    "313, 381, 383, 295, 96, 157, 8, 370, 123, 291, 298, 4, 227, 394, 349, 128, 150, 225, 175, 93, \n",
    "343, 376, 359, 147, 315, 111, 240, 122, 24, 299, 166, 297, 20, 149, 362, 187, 15, 355, 156, \n",
    "216, 374, 138, 2, 28, 31, 188, 89, 283, 239, 377, 1, 354, 169, 273, 201, 259, 218, 333, 167, \n",
    "318, 342, 358, 290, 345, 214, 88, 141, 253, 73, 270, 129, 351, 199, 260, 252, 282, 329, 289, 116, \n",
    "350, 121, 339, 115, 296, 84, 131, 279, 57, 155, 266, 390, 37, 231, 248, 9, 58, 117, 263, 308, 302, \n",
    "153, 285, 369, 40, 192, 222, 215, 388, 162, 124, 120, 34, 52, 183, 173, 365, 98, 200, 49, 159, 151, \n",
    "312, 228, 207, 348, 92, 366, 235, 320, 22, 130, 178, 202, 326, 378, 11, 294, 179, 10, 380, 205, \n",
    "194, 328, 392, 25, 386, 311, 303, 87, 269, 224, 127, 363, 135, 90, 64, 256, 337, 32, 146, 145, 184, \n",
    "56, 100, 206, 97, 356, 95, 74, 317, 344, 319, 45, 340, 307, 132, 3, 81, 108, 232, 112, 148, 242, 163, \n",
    "213, 361, 38, 223, 142, 27, 83, 276, 105, 0, 245, 59, 262, 29, 198, 373, 65, 101, 221, 332, 275, 43, 251, \n",
    "191, 125, 219, 71, 250, 19, 309, 53, 182, 21, 230, 322, 341, 186, 16, 26, 208, 244, 42, 48, \n",
    "86, 134, 171, 103, 237, 379]\n",
    "\n",
    "training_data = df.iloc[training_indices]\n",
    "testing_data = df.iloc[[i for i in range(len(df)) if i not in training_indices]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of features as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_grade_features(df):\n",
    "    result = df[['failures', 'G1', 'G2', 'G3']]\n",
    "    result[\"sex\"] = (df[\"sex\"] == \"male\").astype(int)\n",
    "    result[\"school\"] = (df[\"school\"] == \"GP\").astype(int)\n",
    "    return result\n",
    "\n",
    "df_to_grade_features(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_predict_features(df):\n",
    "    result = df[['failures', 'G1', 'G2']]\n",
    "    result[\"sex\"] = (df[\"sex\"] == \"male\").astype(int)\n",
    "    result[\"school\"] = (df[\"school\"] == \"GP\").astype(int)\n",
    "    result[\"accept\"] = (df[\"G3\"] >= 15).astype(int)\n",
    "    return result\n",
    "\n",
    "df_to_predict_features(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import scikit-learn and build a random forest classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grade_model(data):\n",
    "    dependent_variable = 'G3'\n",
    "    features = df_to_grade_features(data)\n",
    "    x = features[features.columns.difference([dependent_variable])]\n",
    "    y = features[dependent_variable]\n",
    "    clf = rf(n_estimators = 1000)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "    \n",
    "grade_model = make_grade_model(training_data)\n",
    "joblib.dump(grade_model, 'app/handlers/grade_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_model(data):\n",
    "    dependent_variable = 'accept'\n",
    "    features = df_to_predict_features(data)\n",
    "    x = features[features.columns.difference([dependent_variable])]\n",
    "    y = features[dependent_variable]\n",
    "    clf = rf(n_estimators = 1000)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "    \n",
    "predict_model = make_predict_model(training_data)\n",
    "joblib.dump(predict_model, 'app/handlers/predict_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grade_model(data):\n",
    "    dependent_variable = 'G3'\n",
    "    features = df_to_grade_features(testing_data)\n",
    "    x = features[features.columns.difference([dependent_variable])]\n",
    "    y = features[dependent_variable]\n",
    "    pred = grade_model.predict(x)\n",
    "    return pd.DataFrame({\"Answer\": pred, \"Expected\": y, \"Error\": abs(pred - y)})\n",
    "\n",
    "grade_outcome = test_grade_model(testing_data)\n",
    "grade_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_outcome[\"Error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_model(data):\n",
    "    dependent_variable = 'accept'\n",
    "    features = df_to_predict_features(testing_data)\n",
    "    x = features[features.columns.difference([dependent_variable])]\n",
    "    y = features[dependent_variable]\n",
    "    pred = predict_model.predict(x)\n",
    "    return pd.DataFrame({\"Answer\": pred, \"Expected\": y, \"Error\": abs(pred - y)})\n",
    "\n",
    "predict_outcome = test_predict_model(testing_data)\n",
    "predict_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_outcome[\"Error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "22af72542bd729f941fa8b0e250217bc2f6fa0192c444240fec21c15d18c1c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
